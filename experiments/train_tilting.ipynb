{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Это эксперимент по обучению модели на определение угла наклона. Синтетически поворачиваем фотографию и обучаем предсказывать угол наклона.\n",
    "\n",
    "## Что-то выучил, но в целом, не очень хорошо. Возможно, нужно пересмотреть аугментацию, взять чистые данные, что-то сделать с моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import glob\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class RotationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, image_paths, epoch_size=512, target_size=(224, 224), is_val=False\n",
    "    ):\n",
    "        self.all_image_paths = image_paths\n",
    "        self.epoch_size = epoch_size\n",
    "        self.image_paths = []\n",
    "        self.target_size = target_size\n",
    "        self.is_val = is_val\n",
    "        self.shuffle_and_select()\n",
    "\n",
    "        if self.is_val:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize(self.target_size),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def shuffle_and_select(self):\n",
    "        if len(self.all_image_paths) > self.epoch_size:\n",
    "            self.image_paths = random.sample(self.all_image_paths, self.epoch_size)\n",
    "        else:\n",
    "            self.image_paths = self.all_image_paths\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_paths[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if not self.is_val:\n",
    "            angle_max = 60\n",
    "            angle = random.uniform(-angle_max, angle_max)\n",
    "            img_pil = TF.to_pil_image(img)\n",
    "            img_rotated = TF.rotate(img_pil, angle, expand=True)\n",
    "\n",
    "            # Calculate larger crop size dynamically based on rotation\n",
    "            original_size = img_rotated.size\n",
    "            scale_factor = 1.3  # Adjust this factor based on how much larger you want the crop to be\n",
    "            larger_crop_size = (\n",
    "                int(self.target_size[0] * scale_factor),\n",
    "                int(self.target_size[1] * scale_factor),\n",
    "            )\n",
    "            img_cropped = TF.center_crop(img_rotated, larger_crop_size)\n",
    "\n",
    "            # Resize to the target size\n",
    "            img_resized = TF.resize(img_cropped, self.target_size)\n",
    "        else:\n",
    "            img_resized = TF.to_pil_image(img)\n",
    "            angle = 0\n",
    "\n",
    "        img_transformed = self.transform(img_resized)\n",
    "\n",
    "        return img_transformed, torch.tensor(angle, dtype=torch.float32), img_path\n",
    "\n",
    "\n",
    "# Load image paths\n",
    "image_paths = glob.glob(\"../data/real_estate_images/*.jpg\")\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = RotationDataset(image_paths)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "model.classifier[1] = nn.Linear(model.last_channel, 1)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(ax, inp, title=None):\n",
    "    \"\"\"Imshow for Tensor on a given axes.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean  # denormalize\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "dataset = RotationDataset(image_paths, is_val=False)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "# Get a batch of training data\n",
    "images, angles, paths = next(iter(dataloader))\n",
    "\n",
    "# Plot images in a 3x3 grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i < len(images):  # Check to avoid IndexError if fewer images than subplots\n",
    "        img = images[i]\n",
    "        angle = angles[i]\n",
    "        imshow(ax, img, title=f\"Angle: {angle:.2f}\")\n",
    "    else:\n",
    "        ax.axis(\"off\")  # Turn off axis for empty subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "dataset = RotationDataset(epoch_size=4 * 1024, image_paths=image_paths)\n",
    "for epoch in range(num_epochs):\n",
    "    dataset.shuffle_and_select()  # Shuffle and select new images for this epoch\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, angles, paths in dataloader:\n",
    "        images = images.to(device)\n",
    "        angles = angles.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), angles)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # в отдельной валидации потребности нет\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    mae = np.sqrt(epoch_loss)  # Calculate MAE as the square root of MSE\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f}, MAE: {mae:.2f} degrees\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect defects in real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "dataset = RotationDataset(image_paths, epoch_size=5000, is_val=True)\n",
    "dataset.shuffle_and_select()\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return img_tensor * std + mean\n",
    "\n",
    "\n",
    "def visualize_predictions(dataset, model, num_images=25, threshold=20):\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(dataset)):\n",
    "        img, _, _ = dataset[i]\n",
    "        img_tensor = img.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_angle = model(img_tensor).item()\n",
    "\n",
    "        if abs(predicted_angle) > threshold:\n",
    "            img = denormalize(img)\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "            img_height, img_width, _ = img.shape\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "            axes[count].imshow(img)\n",
    "            axes[count].set_title(f\"Predicted: {predicted_angle:.2f}°\")\n",
    "            axes[count].axis(\"off\")\n",
    "\n",
    "            # Add a red thin line across the entire image\n",
    "            angle_rad = np.deg2rad(predicted_angle)\n",
    "            line_start = (0, int(img_height / 2 - img_width / 2 * np.tan(angle_rad)))\n",
    "            line_end = (\n",
    "                img_width,\n",
    "                int(img_height / 2 + img_width / 2 * np.tan(angle_rad)),\n",
    "            )\n",
    "            axes[count].plot(\n",
    "                [line_start[0], line_end[0]],\n",
    "                [line_start[1], line_end[1]],\n",
    "                \"r-\",\n",
    "                linewidth=1,\n",
    "            )\n",
    "\n",
    "            # Add a perpendicular line to form a red cross\n",
    "            perp_angle_rad = angle_rad + np.pi / 2\n",
    "            center_x, center_y = img_width / 2, img_height / 2\n",
    "            line_length = min(img_width, img_height) / 2\n",
    "            perp_line_start_x = center_x - line_length * np.cos(perp_angle_rad)\n",
    "            perp_line_start_y = center_y - line_length * np.sin(perp_angle_rad)\n",
    "            perp_line_end_x = center_x + line_length * np.cos(perp_angle_rad)\n",
    "            perp_line_end_y = center_y + line_length * np.sin(perp_angle_rad)\n",
    "\n",
    "            axes[count].plot(\n",
    "                [perp_line_start_x, perp_line_end_x],\n",
    "                [perp_line_start_y, perp_line_end_y],\n",
    "                \"r-\",\n",
    "                linewidth=1,\n",
    "            )\n",
    "\n",
    "            count += 1\n",
    "            # print(count)\n",
    "\n",
    "            if count == num_images:\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_predictions(dataset, model, threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но у нас модели будут оцениваться в скрипте через докер и прочее, чтобы быть ближе к реальным условиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# dataset = RotationDataset(image_paths, epoch_size=10000, is_val=False)\n",
    "\n",
    "\n",
    "# def benchmark_model(model, dataset, num_batches=10, batch_size=32):\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "#     model.eval()\n",
    "#     device = next(model.parameters()).device  # Get the device model is on\n",
    "\n",
    "#     times = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for i, (images, labels, paths) in enumerate(dataloader):\n",
    "#             if i >= num_batches:\n",
    "#                 break\n",
    "#             start_time = time.time()\n",
    "#             images = images.to(device)\n",
    "#             outputs = model(images)\n",
    "#             predictions = torch.sigmoid(outputs)\n",
    "#             end_time = time.time()\n",
    "\n",
    "#             times.append(end_time - start_time)\n",
    "\n",
    "#     # Calculate the average time per batch and images per second\n",
    "#     avg_time_per_batch = sum(times) / len(times)\n",
    "#     images_per_second = batch_size / avg_time_per_batch\n",
    "\n",
    "#     print(f\"Average time per batch: {avg_time_per_batch:.3f} seconds\")\n",
    "#     print(f\"Images processed per second: {images_per_second:.2f}\")\n",
    "\n",
    "#     return images_per_second\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# images_per_second = benchmark_model(model, dataset, num_batches=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_save_path = \"mobilenet_v2_tilting.pth\"\n",
    "\n",
    "# torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loaded = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "# model_loaded.classifier[1] = nn.Linear(model_loaded.last_channel, 1)\n",
    "# model_loaded.to(device)\n",
    "\n",
    "# model_weights_path = 'mobilenet_v2_tilting.pth'\n",
    "# model_loaded.load_state_dict(torch.load(model_weights_path))\n",
    "# model_loaded.eval()  # Set the model to evaluation mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
