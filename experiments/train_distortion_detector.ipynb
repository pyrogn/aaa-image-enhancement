{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Это попытка заспидранить обучение легковесного классификатора дефектов через чач бота. Можно смело переписывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оно что-то учит, но пока что плоховато и есть большой потенциал для улучшения. Но перед этим не помешает пересмотреть код генерации синтетики и иметь хорошие данные (профессиональные)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумать о кропе, так как случайный кроп для инференса нас не устроит... Но полноразмерная картинка, сжатая до 224x224 теряет детали и добавляет дефекты через интерполяцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotation не работает, так как он учит черный цвет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from aaa_image_enhancement.image_defects_detection import DefectNames\n",
    "from aaa_image_enhancement.image_utils import ImageConversions\n",
    "from aaa_image_enhancement.synth_defects import ImageDistortions\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "\n",
    "# подумать о шафле\n",
    "class DefectsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_paths,\n",
    "        apply_distortions=True,\n",
    "        epoch_size=512,\n",
    "        target_size=(224, 224),\n",
    "    ):\n",
    "        self.all_image_paths = image_paths\n",
    "        self.epoch_size = epoch_size\n",
    "        self.apply_distortions = apply_distortions\n",
    "        self.image_paths = []\n",
    "        self.shuffle_and_select()\n",
    "        self.target_size = target_size\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(\n",
    "                    self.target_size, interpolation=InterpolationMode.BILINEAR\n",
    "                ),\n",
    "                transforms.RandomRotation(10),\n",
    "                # transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        self.val_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(\n",
    "                    self.target_size, interpolation=InterpolationMode.BILINEAR\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def shuffle_and_select(self):\n",
    "        # Randomly select a subset of image paths for this epoch\n",
    "        if len(self.all_image_paths) > self.epoch_size:\n",
    "            self.image_paths = random.sample(self.all_image_paths, self.epoch_size)\n",
    "        else:\n",
    "            self.image_paths = self.all_image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_paths[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = ImageConversions.changeBR(img)  # Convert BGR to RGB\n",
    "\n",
    "        while img.shape[0] < 224 or img.shape[1] < 224:\n",
    "            index = random.randint(0, len(self.image_paths) - 1)\n",
    "            img_path = self.image_paths[index]\n",
    "            img = cv2.imread(img_path)\n",
    "            img = ImageConversions.changeBR(img)  # Convert BGR to RGB\n",
    "\n",
    "        # Randomly apply distortions\n",
    "        if self.apply_distortions and random.random() < 0.5:\n",
    "            distorter = ImageDistortions(img)\n",
    "            distortions = random.sample(list(DefectNames), 1)  # increase later\n",
    "            distorted_img, applied_distortions = distorter.apply_distortions(\n",
    "                distortions\n",
    "            )\n",
    "            img = distorted_img\n",
    "            # check carefully, does Enum have order? If not, fix it.\n",
    "            labels = [\n",
    "                1 if defect in applied_distortions else 0 for defect in DefectNames\n",
    "            ]\n",
    "        else:\n",
    "            labels = [0] * len(DefectNames)\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.apply_distortions:  # val\n",
    "            img = self.val_transform(img)\n",
    "        else:  # train\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(labels, dtype=torch.float32), img_path\n",
    "\n",
    "\n",
    "# Load image paths\n",
    "image_paths = glob.glob(\"../data/real_estate_images/*.jpg\")\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = DefectsDataset(image_paths, epoch_size=512)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)  # no need\n",
    "\n",
    "# Define the model\n",
    "# model = mobilenet_v2(\n",
    "#     num_classes=len(DefectNames)\n",
    "# )\n",
    "model = mobilenet_v2(  # do we need weights?\n",
    "    weights=torchvision.models.MobileNet_V2_Weights\n",
    ")\n",
    "model.classifier[1] = nn.Linear(model.last_channel, len(DefectNames))\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## watch labels of real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "# Assuming dataset and dataloader are already defined and initialized\n",
    "dataset = DefectsDataset(image_paths)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=32, shuffle=True\n",
    ")  # Ensure there's enough data\n",
    "\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean  # denormalize\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=8)\n",
    "    plt.axis(\"off\")  # Turn off axis numbers and ticks\n",
    "\n",
    "\n",
    "def process_image(inp):\n",
    "    \"\"\"Process a Tensor for displaying.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean  # denormalize\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "\n",
    "# Assuming dataset and dataloader are already defined and initialized\n",
    "dataset = DefectsDataset(image_paths)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=32, shuffle=True\n",
    ")  # Ensure there's enough data\n",
    "\n",
    "# Get a batch of training data\n",
    "images, labels, _ = next(iter(dataloader))\n",
    "\n",
    "# Get random indices to display 9 images\n",
    "indices = torch.randperm(images.size(0))[:9]\n",
    "\n",
    "# Prepare titles with defect names\n",
    "titles = [\n",
    "    \", \".join(\n",
    "        [\n",
    "            defect.name\n",
    "            for defect, present in zip(DefectNames, labels[idx])\n",
    "            if present == 1\n",
    "        ]\n",
    "    )\n",
    "    for idx in indices\n",
    "]\n",
    "\n",
    "# Plot images in a 3x3 grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, (ax, idx) in enumerate(zip(axes.flatten(), indices)):\n",
    "    img = process_image(images[idx])  # Process the image for display\n",
    "    ax.imshow(img)  # Use Matplotlib's imshow\n",
    "    ax.set_title(titles[i], fontsize=8)\n",
    "    ax.axis(\"off\")  # Hide axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    dataset.shuffle_and_select()  # Shuffle and select new images for this epoch\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for images, labels, paths in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation and metrics calculation\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "\n",
    "    # Calculate metrics for each class\n",
    "    f1_scores = [\n",
    "        f1_score(all_labels[:, i], all_predictions[:, i] > 0.5)\n",
    "        for i in range(len(DefectNames))\n",
    "    ]\n",
    "    average_f1_score = np.mean(f1_scores)  # type: ignore\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item():.2f}, Average F1 Score: {average_f1_score:.4f}, \"\n",
    "        + \", \".join(\n",
    "            f\"{defect.name} F1: {f1:.4f}\" for defect, f1 in zip(DefectNames, f1_scores)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_to_index = {defect: index for index, defect in enumerate(DefectNames)}\n",
    "index_to_defect = {index: defect for index, defect in enumerate(DefectNames)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect defects in real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "dataset = DefectsDataset(image_paths, epoch_size=10000, apply_distortions=False)\n",
    "\n",
    "\n",
    "def find_defective_images(model, dataset, defect_index, threshold=0.8, num_images=10):\n",
    "    model.eval()\n",
    "    found_images = []\n",
    "    found_paths = []  # List to save the paths of detected images\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "\n",
    "            probs = predictions[:, defect_index]\n",
    "            indices = (probs > threshold).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            for idx in indices:\n",
    "                if len(found_images) >= num_images:\n",
    "                    break\n",
    "                found_images.append(paths[idx])\n",
    "                print(paths[idx])\n",
    "                found_paths.append(paths[idx])  # Save the path\n",
    "\n",
    "            if len(found_images) >= num_images:\n",
    "                break\n",
    "\n",
    "    # Display the found images\n",
    "    for img_path in found_images:\n",
    "        img = Image.open(img_path)\n",
    "        display(img)\n",
    "\n",
    "    return found_paths  # Return the list of paths for later review\n",
    "\n",
    "\n",
    "detected_paths = find_defective_images(\n",
    "    model, dataset, defect_to_index[DefectNames.BLUR], threshold=0.7, num_images=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но у нас модели будут оцениваться в скрипте через докер и прочее, чтобы быть ближе к реальным условиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = DefectsDataset(image_paths, epoch_size=10000, apply_distortions=False)\n",
    "\n",
    "\n",
    "def benchmark_model(model, dataset, num_batches=10, batch_size=32):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device  # Get the device model is on\n",
    "\n",
    "    times = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels, paths) in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            start_time = time.time()\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            end_time = time.time()\n",
    "\n",
    "            times.append(end_time - start_time)\n",
    "\n",
    "    # Calculate the average time per batch and images per second\n",
    "    avg_time_per_batch = sum(times) / len(times)\n",
    "    images_per_second = batch_size / avg_time_per_batch\n",
    "\n",
    "    print(f\"Average time per batch: {avg_time_per_batch:.3f} seconds\")\n",
    "    print(f\"Images processed per second: {images_per_second:.2f}\")\n",
    "\n",
    "    return images_per_second\n",
    "\n",
    "\n",
    "# Example usage\n",
    "images_per_second = benchmark_model(model, dataset, num_batches=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
